{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JMAK3yD023O"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import math\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import optax\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import floyd_warshall\n",
    "from collections import deque\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7O-mP031BuX"
   },
   "outputs": [],
   "source": [
    "class GraphIntegrator():\n",
    "  # * f_func: function of signature R -> R; either given as lambda or a a pair\n",
    "  #     of two lists ([a_0, a_1,...,a_{t-1}], [b_0, b_1,..., b_{r-1}]). In the\n",
    "  #     latter case, the lists encode a rational function:\n",
    "  #\n",
    "  #        f(x) = (a_0 + a_1 * x + ... + a_{t-1} * x^{t-1}) /\n",
    "  #               (b_0 + b_1 * x + ... + b_{r-1} * x^{r-1})\n",
    "  #\n",
    "  #\n",
    "  # * is_lambda: boolean indicating whether f_func above is given as a lambda\n",
    "  #     or a pair of two lists of coefficients (as described above)\n",
    "  # * graph_adj_lists: the adjacency lists encoding weighted undirected graph:\n",
    "  #     graph_adj_lists[i][j] is a pair of the form (k, w), where k is the id\n",
    "  #     of the jth neighbor of i (we start counting from 0) and w is the weight\n",
    "  #     of an edge connecting i with k. We assume that graph nodes have\n",
    "  #     identifiers: 0, 1, 2, ..., N-1, where N is the number of the nodes of\n",
    "  #     the graph.\n",
    "  def __init__(self, f_func, is_lambda, graph_adj_lists):\n",
    "    self.f_func = f_func\n",
    "    self.is_lambda = is_lambda\n",
    "    self.graph_adj_lists = graph_adj_lists\n",
    "    self.N = len(graph_adj_lists)\n",
    "  # * X_tensor: tensor of the shape: N x b_1 x b_2 x ... b_s, where: N is the\n",
    "  #     number of nodes of the graph and b_1, b_2, ... b_s are sizes of batch\n",
    "  #     dimensions (arbitrary number of them).\n",
    "  # * Output: Tensor Y = einsum(\"mn,n...->m...\", M, X_tensor), where M is the\n",
    "  #     N x N matrix satisfying: M[i][j] ~ f_func(dist(i,j)) and dist is the\n",
    "  #     shortest path distance between i and j in the graph.\n",
    "  def integrate(self, X_tensor):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-T8qmO7n1H4c"
   },
   "outputs": [],
   "source": [
    "# Auxiliary functions for the brute-force integrator.\n",
    "def compute_shortest_path_distances(graph_adj_lists):\n",
    "  N = len(graph_adj_lists)\n",
    "  edges = np.zeros((N, N))\n",
    "  for i in range(N):\n",
    "    for j, w in graph_adj_lists[i]:\n",
    "      edges[i,j] = w\n",
    "      edges[j,i] = w\n",
    "  csr_adjacency = csr_matrix(edges)\n",
    "  return floyd_warshall(csgraph=csr_adjacency, directed=False)\n",
    "\n",
    "def poly(x, coeff_list):\n",
    "  accum = 0\n",
    "  x_power = 1\n",
    "  for i in range(len(coeff_list)):\n",
    "    accum += x_power * coeff_list[i]\n",
    "    x_power *= x\n",
    "  return accum\n",
    "\n",
    "class BruteForceGraphIntegrator(GraphIntegrator):\n",
    "  def __init__(self, f_func, is_lambda, graph_adj_lists):\n",
    "    super().__init__(f_func, is_lambda, graph_adj_lists)\n",
    "    self.M = compute_shortest_path_distances(self.graph_adj_lists)\n",
    "    for i in range(self.N):\n",
    "      for j in range(self.N):\n",
    "        if not self.is_lambda:\n",
    "          numerator = poly(self.M[i][j], self.f_func[0])\n",
    "          denominator = poly(self.M[i][j], self.f_func[1])\n",
    "          self.M[i][j] = numerator / denominator\n",
    "        else:\n",
    "          self.M[i][j] = self.f_func(self.M[i][j])\n",
    "  def integrate(self, X_tensor):\n",
    "    return np.einsum(\"mn,n...->m...\", self.M, X_tensor)\n",
    "  def get_m_matrix(self):\n",
    "    return self.M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jw7ENTx1Pjq"
   },
   "outputs": [],
   "source": [
    "# Low-level auxiliary functions for main auxiliary functions:\n",
    "#\n",
    "# 1. integrate_on_tree,\n",
    "# 2. preprocess_tree,\n",
    "# 3. partition_tree,\n",
    "# 4. compute_struct_for_merge.\n",
    "#\n",
    "class CompTree():\n",
    "  def __init__(self, left_child, right_child, left_id_sets, right_id_sets,\n",
    "               left_distances, right_distances, left_ids, right_ids, bfgi):\n",
    "    self.left_child = left_child\n",
    "    self.right_child = right_child\n",
    "    ### Fields containing content.\n",
    "    self.left_id_sets = left_id_sets\n",
    "    self.right_id_sets = right_id_sets\n",
    "    self.left_distances = left_distances\n",
    "    self.right_distances = right_distances\n",
    "    self.left_ids = left_ids\n",
    "    self.right_ids = right_ids\n",
    "    self.bfgi = bfgi\n",
    "\n",
    "def find_vertices(tree, root):\n",
    "  found_vertices = []\n",
    "  parent = np.zeros(len(tree))\n",
    "  parent[root] = -1\n",
    "  queue = deque([root])\n",
    "  while queue:\n",
    "    m = queue.pop()\n",
    "    for neighbour, weight in tree[m]:\n",
    "      if neighbour != parent[m]:\n",
    "        found_vertices.append(neighbour)\n",
    "        queue.append(neighbour)\n",
    "        parent[neighbour] = m\n",
    "  return found_vertices\n",
    "\n",
    "def bfs(graph, start):\n",
    "  visited = np.zeros(len(graph))\n",
    "  distances = np.zeros(len(graph))\n",
    "  queue = deque([])\n",
    "  def bfs_aux(graph, node, visited, distances, queue):\n",
    "    visited[node] = 1\n",
    "    queue.append(node)\n",
    "    while queue:\n",
    "      m = queue.pop()\n",
    "      for neighbour, weight in graph[m]:\n",
    "        if visited[neighbour] == 0:\n",
    "          visited[neighbour] = 1\n",
    "          distances[neighbour] = distances[m] + weight\n",
    "          queue.append(neighbour)\n",
    "    return distances\n",
    "  return bfs_aux(graph, start, visited, distances, queue)\n",
    "\n",
    "def dfs_subtree_sizes(tree, root):\n",
    "  stack = []\n",
    "  sizes = np.zeros(len(tree))\n",
    "  discovered = np.zeros(len(tree))\n",
    "  parent = np.zeros(len(tree), dtype=int)\n",
    "  parent[root] = root\n",
    "  stack.append(root)\n",
    "  while len(stack) > 0:\n",
    "    vertex = stack[-1]\n",
    "    if not discovered[vertex]:\n",
    "      sizes[vertex] += 1\n",
    "      discovered[vertex] = 1\n",
    "      count = 0\n",
    "      for neighbor_weight in tree[vertex]:\n",
    "        neighbor = neighbor_weight[0]\n",
    "        if neighbor != parent[vertex]:\n",
    "          count += 1\n",
    "          stack.append(neighbor)\n",
    "          parent[neighbor] = vertex\n",
    "      if not count:\n",
    "        sizes[parent[vertex]] += sizes[vertex]\n",
    "        x = stack.pop()\n",
    "    else:\n",
    "      if vertex is not root:\n",
    "        sizes[parent[vertex]] += sizes[vertex]\n",
    "      x = stack.pop()\n",
    "  return sizes\n",
    "\n",
    "class Level():\n",
    "  def __init__(self, tf_shape):\n",
    "    self.nodes = []\n",
    "    if tf_shape is not None:\n",
    "      self.tf_value = np.zeros(tf_shape)\n",
    "\n",
    "def compute_cross_contribs(left_distances, left_tf_vals, right_distances,\n",
    "                           right_tf_vals, f_func, is_lambda):\n",
    "  if is_lambda:\n",
    "    left_struct_matrix = np.zeros((len(left_distances), len(right_distances)))\n",
    "    for i in range(len(left_distances)):\n",
    "      for j in range(len(right_distances)):\n",
    "        left_struct_matrix[i][j] = f_func(left_distances[i] + right_distances[j])\n",
    "    right_struct_matrix = np.transpose(left_struct_matrix)\n",
    "    cross_vals_for_left = np.einsum(\"kl,l...->k...\", left_struct_matrix,\n",
    "                                    np.array(right_tf_vals))\n",
    "    cross_vals_for_right = np.einsum(\"lk,k...->l...\", right_struct_matrix,\n",
    "                                     np.array(left_tf_vals))\n",
    "  else:\n",
    "    a, b = f_func\n",
    "    if (len(b) == 1 and b[0] == 1.0):\n",
    "      l_res_shape = tuple([len(left_distances)] +\n",
    "                          list(np.array(right_tf_vals).shape[1:]))\n",
    "      r_res_shape = tuple([len(right_distances)] +\n",
    "                          list(np.array(left_tf_vals).shape[1:]))\n",
    "      cross_vals_for_left = np.zeros(l_res_shape)\n",
    "      cross_vals_for_right = np.zeros(r_res_shape)\n",
    "      for k in range(len(a)):\n",
    "        for b in range(k + 1):\n",
    "          l_array = np.array([np.power(l, b) for l in left_distances])\n",
    "          r_array = np.array([np.power(r, k - b) for r in right_distances])\n",
    "          renorm = a[k] * math.comb(k, b)\n",
    "          cross_vals_for_left += renorm * np.einsum(\"n,m,m...->n...\", l_array,\n",
    "                                                    r_array,\n",
    "                                                    np.array(right_tf_vals))\n",
    "          cross_vals_for_right += renorm * np.einsum(\"m,n,n...->m...\", r_array,\n",
    "                                                     l_array,\n",
    "                                                     np.array(left_tf_vals))\n",
    "\n",
    "  return cross_vals_for_left, cross_vals_for_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ee3F2c1V1agP"
   },
   "outputs": [],
   "source": [
    "# Main auxiliary functions.\n",
    "def partition_tree(original_tree):\n",
    "  tree = copy.deepcopy(original_tree)\n",
    "  root = 0\n",
    "  pivot_point = 0\n",
    "  parent = np.zeros(len(tree), dtype=int)\n",
    "  parent[root] = -1\n",
    "  sizes = dfs_subtree_sizes(tree, root)\n",
    "  queue = deque([root])\n",
    "  while queue:\n",
    "    m = queue.pop()\n",
    "    if sizes[m] > 0.5 * len(tree):\n",
    "      pivot_point = m\n",
    "    for neighbour, _ in tree[m]:\n",
    "      if neighbour != parent[m]:\n",
    "        queue.append(neighbour)\n",
    "        parent[neighbour] = m\n",
    "  sizes[parent[pivot_point]] = len(tree) - sizes[pivot_point]\n",
    "  acc = 0\n",
    "  index = -1\n",
    "  for neighbor, _ in tree[pivot_point]:\n",
    "    if acc > 0.25 * len(tree):\n",
    "      break\n",
    "    else:\n",
    "      acc += sizes[neighbor]\n",
    "      index += 1\n",
    "  left_neighbors = copy.deepcopy(tree[pivot_point][:(index + 1)])\n",
    "  right_neighbors = copy.deepcopy(tree[pivot_point][(index + 1):])\n",
    "  tree[pivot_point] = left_neighbors\n",
    "  left_vertex_set = find_vertices(tree, pivot_point)\n",
    "  if_left_vertex = np.zeros(len(tree), dtype=int)\n",
    "  for elem in left_vertex_set:\n",
    "    if_left_vertex[elem] = 1\n",
    "  left_tree = [left_neighbors]\n",
    "  left_ids = [pivot_point]\n",
    "  right_tree = [right_neighbors]\n",
    "  right_ids = [pivot_point]\n",
    "  for i in range(len(if_left_vertex)):\n",
    "    if i == pivot_point:\n",
    "      continue\n",
    "    if if_left_vertex[i]:\n",
    "      left_tree.append(copy.deepcopy(tree[i]))\n",
    "      left_ids.append(i)\n",
    "    else:\n",
    "      right_tree.append(copy.deepcopy(tree[i]))\n",
    "      right_ids.append(i)\n",
    "  inv_left_ids = np.zeros(len(tree))\n",
    "  inv_right_ids = np.zeros(len(tree))\n",
    "  for i in range(len(left_ids)):\n",
    "    inv_left_ids[left_ids[i]] = i\n",
    "  for i in range(len(right_ids)):\n",
    "    inv_right_ids[right_ids[i]] = i\n",
    "  for i in range(len(left_tree)):\n",
    "    for j in range(len(left_tree[i])):\n",
    "      left_tree[i][j][0] = int(inv_left_ids[left_tree[i][j][0]])\n",
    "  for i in range(len(right_tree)):\n",
    "    for j in range(len(right_tree[i])):\n",
    "      right_tree[i][j][0] = int(inv_right_ids[right_tree[i][j][0]])\n",
    "  return [left_tree, left_ids, right_tree, right_ids]\n",
    "\n",
    "\n",
    "def integrate_cross_terms(left_id_sets, right_id_sets, left_distances,\n",
    "                          right_distances, f_func, is_lambda, X_tensor,\n",
    "                          Y_tensor):\n",
    "  left_tf_vals = []\n",
    "  right_tf_vals = []\n",
    "  for i in range(len(left_id_sets)):\n",
    "    left_tf_vals.append(np.sum(X_tensor[left_id_sets[i],:], axis=0,\n",
    "                               keepdims=False))\n",
    "  for i in range(len(right_id_sets)):\n",
    "    right_tf_vals.append(np.sum(X_tensor[right_id_sets[i],:], axis=0,\n",
    "                                keepdims=False))\n",
    "  res = compute_cross_contribs(left_distances, left_tf_vals, right_distances,\n",
    "                               right_tf_vals, f_func, is_lambda)\n",
    "  cross_vals_for_left = res[0]\n",
    "  cross_vals_for_right = res[1]\n",
    "  for i in range(len(cross_vals_for_left)):\n",
    "    A = cross_vals_for_left[i]\n",
    "    N = len(left_id_sets[i])\n",
    "    fin_shape = tuple([N] + [1] * len(A.shape))\n",
    "    Y_tensor[left_id_sets[i],:] += np.tile(A, fin_shape)\n",
    "  for i in range(len(cross_vals_for_right)):\n",
    "    A = cross_vals_for_right[i]\n",
    "    N = len(right_id_sets[i])\n",
    "    fin_shape = tuple([N] + [1] * len(A.shape))\n",
    "    Y_tensor[right_id_sets[i],:] += np.tile(A, fin_shape)\n",
    "  return Y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_fwVKrJ1lpN"
   },
   "outputs": [],
   "source": [
    "def compute_struct_for_merge(left_tree, left_ids, right_tree, right_ids):\n",
    "  left_distances = bfs(left_tree, 0)\n",
    "  right_distances = bfs(right_tree, 0)\n",
    "  left_dict = dict()\n",
    "  right_dict = dict()\n",
    "  for i in range(len(left_distances)):\n",
    "    if left_distances[i] > 0.0:\n",
    "      if left_distances[i] not in left_dict:\n",
    "        left_dict[left_distances[i]] = Level(None)\n",
    "      (left_dict[left_distances[i]].nodes).append(left_ids[i])\n",
    "  for i in range(len(right_distances)):\n",
    "    if right_distances[i] > 0.0:\n",
    "      if right_distances[i] not in right_dict:\n",
    "        right_dict[right_distances[i]] = Level(None)\n",
    "      (right_dict[right_distances[i]].nodes).append(right_ids[i])\n",
    "  left_dict_keys = list(left_dict.keys())\n",
    "  left_dict_nodes = [x.nodes for x in list(left_dict.values())]\n",
    "  right_dict_keys = list(right_dict.keys())\n",
    "  right_dict_nodes = [x.nodes for x in list(right_dict.values())]\n",
    "  return left_dict_keys, left_dict_nodes, right_dict_keys, right_dict_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Q4LcWV21uoH"
   },
   "outputs": [],
   "source": [
    "def preprocess_tree(tree, f_func, is_lambda, threshold=6):\n",
    "  if len(tree) < threshold:\n",
    "    bfgi = BruteForceGraphIntegrator(f_func, is_lambda, tree)\n",
    "    return CompTree(None, None, None, None, None, None, None, None, bfgi)\n",
    "  else:\n",
    "    left_tree, left_ids, right_tree, right_ids = partition_tree(tree)\n",
    "    left_child = preprocess_tree(left_tree, f_func, is_lambda, threshold)\n",
    "    right_child = preprocess_tree(right_tree, f_func, is_lambda, threshold)\n",
    "    l_ds, l_ns, r_ds, r_ns = compute_struct_for_merge(left_tree, left_ids,\n",
    "                                                      right_tree, right_ids)\n",
    "    return CompTree(left_child, right_child, l_ns, r_ns, l_ds, r_ds, left_ids,\n",
    "                    right_ids, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPiTAN6T1yxH"
   },
   "outputs": [],
   "source": [
    "def integrate_on_tree(comp_tree, X_tensor, f_func, is_lambda):\n",
    "  if comp_tree.bfgi is not None:\n",
    "    return comp_tree.bfgi.integrate(X_tensor)\n",
    "  else:\n",
    "    left_result = integrate_on_tree(comp_tree.left_child,\n",
    "                                    X_tensor[comp_tree.left_ids,:], f_func,\n",
    "                                    is_lambda)\n",
    "    right_result = integrate_on_tree(comp_tree.right_child,\n",
    "                                     X_tensor[comp_tree.right_ids,:], f_func,\n",
    "                                     is_lambda)\n",
    "    Y_tensor = np.zeros_like(X_tensor)\n",
    "    Y_tensor[comp_tree.left_ids,:] += left_result\n",
    "    Y_tensor[comp_tree.right_ids,:] += right_result\n",
    "    integrate_cross_terms(comp_tree.left_id_sets, comp_tree.right_id_sets,\n",
    "                          comp_tree.left_distances, comp_tree.right_distances,\n",
    "                          f_func, is_lambda, X_tensor, Y_tensor)\n",
    "    return Y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhvHySP413cI"
   },
   "outputs": [],
   "source": [
    "# Abstract class for the tree maker.\n",
    "\n",
    "class TreeConstructor():\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def construct_tree(graph_adj_lists):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GC05MrPd17wW"
   },
   "outputs": [],
   "source": [
    "# Minimum spanning tree functions.\n",
    "\n",
    "class DisjointSet:\n",
    "    parent = {}\n",
    "    size = {}\n",
    "    def makeSet(self, n):\n",
    "      for i in range(n):\n",
    "        self.parent[i] = i\n",
    "        self.size[i] = 1\n",
    "    def find(self, k):\n",
    "      if self.parent[k] == k:\n",
    "        return k\n",
    "      return self.find(self.parent[k])\n",
    "    def union(self, a, b):\n",
    "      x = self.find(a)\n",
    "      y = self.find(b)\n",
    "      if self.size[x] > self.size[y]:\n",
    "        self.parent[y] = x\n",
    "        self.size[x] += self.size[y]\n",
    "      else:\n",
    "        self.parent[x] = y\n",
    "        self.size[y] += self.size[x]\n",
    "\n",
    "def kruskal_algo(graph_adj_lists):\n",
    "  mst = []\n",
    "  tree = []\n",
    "  N = len(graph_adj_lists)\n",
    "  for i in range(N):\n",
    "    tree.append([])\n",
    "  ds = DisjointSet()\n",
    "  ds.makeSet(N)\n",
    "  index = 0\n",
    "  edges = []\n",
    "  for i in range(len(graph_adj_lists)):\n",
    "    for j in range(len(graph_adj_lists[i])):\n",
    "      if graph_adj_lists[i][j][0] < i:\n",
    "        edges.append([i, graph_adj_lists[i][j][0], graph_adj_lists[i][j][1]])\n",
    "  edges.sort(key=lambda x: x[2])\n",
    "  while len(mst) != len(graph_adj_lists) - 1:\n",
    "    src, dest, weight = edges[index]\n",
    "    index = index + 1\n",
    "    x = ds.find(src)\n",
    "    y = ds.find(dest)\n",
    "    if x != y:\n",
    "      tree[src].append([dest, weight])\n",
    "      tree[dest].append([src, weight])\n",
    "      mst.append((src, dest, weight))\n",
    "      ds.union(x, y)\n",
    "  cost = sum([x[2] for x in mst])\n",
    "  return tree\n",
    "\n",
    "class MinimumSpanningTreeConstructor(TreeConstructor):\n",
    "  def __init__(self):\n",
    "    pass\n",
    "  def construct_tree(self, graph_adj_lists):\n",
    "    return kruskal_algo(graph_adj_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jT1gcwaj2CG3"
   },
   "outputs": [],
   "source": [
    "class TreeBasedGraphIntegrator(GraphIntegrator):\n",
    "  def __init__(self, f_func, is_lambda, graph_adj_lists, tree_constructor,\n",
    "               threshold=6):\n",
    "    super().__init__(f_func, is_lambda, graph_adj_lists)\n",
    "    self.tree = tree_constructor.construct_tree(graph_adj_lists)\n",
    "    self.comp_tree = preprocess_tree(self.tree, f_func, is_lambda, threshold)\n",
    "  def integrate(self, X_tensor, threshold=6):\n",
    "    return integrate_on_tree(self.comp_tree, X_tensor, self.f_func,\n",
    "                             self.is_lambda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4jDPPqg2GLB"
   },
   "source": [
    "# TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zNks4_2A2KJN",
    "outputId": "df37034f-5c41-4087-a35a-c7c20b3e6690"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTFI result:\n",
      "[[59.8025]\n",
      " [30.99  ]\n",
      " [33.15  ]\n",
      " [82.4025]\n",
      " [32.1025]\n",
      " [50.9   ]\n",
      " [71.15  ]\n",
      " [93.9   ]\n",
      " [69.8025]]\n",
      "Brute-force integrator result:\n",
      "[[59.8025]\n",
      " [30.99  ]\n",
      " [33.15  ]\n",
      " [82.4025]\n",
      " [32.1025]\n",
      " [50.9   ]\n",
      " [71.15  ]\n",
      " [93.9   ]\n",
      " [69.8025]]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE I\n",
    "\n",
    "a0 = [[3, 0.5], [4, 1.0]]\n",
    "a1 = [[3, 1.5], [4, 0.25], [2, 0.4], [5, 0.7]]\n",
    "a2 = [[1, 0.4], [4, 0.75], [5, 0.5], [8, 2.0], [6, 1.0], [7, 1.5]]\n",
    "a3 = [[1, 1.5], [4, 2.0], [0, 0.5]]\n",
    "a4 = [[0, 1.0], [3, 2.0], [1, 0.25], [2, 0.75], [8, 1.0]]\n",
    "a5 = [[1, 0.7], [2, 0.5]]\n",
    "a6 = [[2, 1.0]]\n",
    "a7 = [[2, 1.5]]\n",
    "a8 = [[4, 1.0], [2, 2.0]]\n",
    "\n",
    "graph = [a0, a1, a2, a3, a4, a5, a6, a7, a8]\n",
    "tree = kruskal_algo(graph)\n",
    "f_func = [[0.0, 2.0, 1.0], [1.0]]\n",
    "tbgi = TreeBasedGraphIntegrator(f_func, False, tree,\n",
    "                                MinimumSpanningTreeConstructor(), threshold=6)\n",
    "bfgi = BruteForceGraphIntegrator(lambda x: 2.0 * x + x * x, True, tree)\n",
    "X = np.ones((len(tree), 1))\n",
    "\n",
    "print(\"FTFI result:\")\n",
    "print(tbgi.integrate(X))\n",
    "print(\"Brute-force integrator result:\")\n",
    "print(bfgi.integrate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnJy3yEq2PKs",
    "outputId": "8a5fca8b-18c4-4c33-ce6c-352ce683e191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTFI result:\n",
      "[[ 86.]\n",
      " [112.]\n",
      " [ 50.]\n",
      " [ 94.]\n",
      " [ 64.]\n",
      " [ 64.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 68.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 68.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 90.]]\n",
      "Brute-force integrator result:\n",
      "[[ 86.]\n",
      " [112.]\n",
      " [ 50.]\n",
      " [ 94.]\n",
      " [ 64.]\n",
      " [ 64.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 68.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 68.]\n",
      " [ 90.]\n",
      " [ 94.]\n",
      " [ 90.]]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE II\n",
    "\n",
    "a0 = [[1,1.0],[4,1.0]]\n",
    "a1 = [[0,1.0]]\n",
    "a2 = [[4,1.0],[8,1.0],[11,1.0],[5,1.0]]\n",
    "a3 = [[8,1.0]]\n",
    "a4 = [[2,1.0],[6,1.0],[0,1.0]]\n",
    "a5 = [[2,1.0],[12,1.0],[14,1.0],[9,1.0]]\n",
    "a6 = [[4,1.0]]\n",
    "a7 = [[11,1.0]]\n",
    "a8 = [[13,1.0],[2,1.0],[3,1.0]]\n",
    "a9 = [[5,1.0]]\n",
    "a10 = [[11,1.0]]\n",
    "a11 = [[2,1.0],[7,1.0],[10,1.0]]\n",
    "a12 = [[5,1.0]]\n",
    "a13 = [[8,1.0]]\n",
    "a14 = [[5,1.0]]\n",
    "\n",
    "tree = [a0, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14]\n",
    "f_func = [[0.0, 2.0], [1.0]]\n",
    "tbgi = TreeBasedGraphIntegrator(f_func, False, tree,\n",
    "                                MinimumSpanningTreeConstructor(), threshold=6)\n",
    "bfgi = BruteForceGraphIntegrator(lambda x: 2.0 * x, True, tree)\n",
    "X = np.ones((len(tree), 1))\n",
    "print(\"FTFI result:\")\n",
    "print(tbgi.integrate(X))\n",
    "print(\"Brute-force integrator result:\")\n",
    "print(bfgi.integrate(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qpmYH-NA2YHV",
    "outputId": "3ea89725-f451-43ff-f2a6-5fbe50f0bed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTFI result:\n",
      "[[235.]\n",
      " [358.]\n",
      " [ 99.]\n",
      " [267.]\n",
      " [146.]\n",
      " [150.]\n",
      " [247.]\n",
      " [267.]\n",
      " [162.]\n",
      " [251.]\n",
      " [267.]\n",
      " [162.]\n",
      " [251.]\n",
      " [267.]\n",
      " [251.]]\n",
      "Brute-force integrator result:\n",
      "[[235.]\n",
      " [358.]\n",
      " [ 99.]\n",
      " [267.]\n",
      " [146.]\n",
      " [150.]\n",
      " [247.]\n",
      " [267.]\n",
      " [162.]\n",
      " [251.]\n",
      " [267.]\n",
      " [162.]\n",
      " [251.]\n",
      " [267.]\n",
      " [251.]]\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE III\n",
    "\n",
    "a0 = [[1,1.0],[4,1.0]]\n",
    "a1 = [[0,1.0]]\n",
    "a2 = [[4,1.0],[8,1.0],[11,1.0],[5,1.0]]\n",
    "a3 = [[8,1.0]]\n",
    "a4 = [[2,1.0],[6,1.0],[0,1.0]]\n",
    "a5 = [[2,1.0],[12,1.0],[14,1.0],[9,1.0]]\n",
    "a6 = [[4,1.0]]\n",
    "a7 = [[11,1.0]]\n",
    "a8 = [[13,1.0],[2,1.0],[3,1.0]]\n",
    "a9 = [[5,1.0]]\n",
    "a10 = [[11,1.0]]\n",
    "a11 = [[2,1.0],[7,1.0],[10,1.0]]\n",
    "a12 = [[5,1.0]]\n",
    "a13 = [[8,1.0]]\n",
    "a14 = [[5,1.0]]\n",
    "\n",
    "graph = [a0, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14]\n",
    "tree = kruskal_algo(graph)\n",
    "f_func = [[0.0, 2.0, 1.0], [1.0]]\n",
    "tbgi = TreeBasedGraphIntegrator(f_func, False, tree,\n",
    "                                MinimumSpanningTreeConstructor(), threshold=6)\n",
    "bfgi = BruteForceGraphIntegrator(lambda x: 2.0 * x + x * x, True, tree)\n",
    "X = np.ones((len(tree), 1))\n",
    "print(\"FTFI result:\")\n",
    "print(tbgi.integrate(X))\n",
    "print(\"Brute-force integrator result:\")\n",
    "print(bfgi.integrate(X))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
